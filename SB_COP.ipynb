{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6f4c893",
   "metadata": {},
   "source": [
    "# Import the Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdab898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Numerical and Data Manipulation Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PDF Handling\n",
    "import PyPDF2\n",
    "\n",
    "# Scikit-Learn for Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Machine Learning Classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, classification_report, confusion_matrix\n",
    "\n",
    "# Sentence Transformers for Sentence Embeddings\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb7680",
   "metadata": {},
   "source": [
    "# Data Preparation and Feature Extraction for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7995b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file and exclude specific columns\n",
    "data_df = pd.read_csv('/Users/l/Desktop/Edinburgh/Dissertation/Session2_SB/Code/data_extracted.csv', \n",
    "                      usecols=lambda column: column in ['decision', 'background'])\n",
    "\n",
    "# Load SentenceTransformer model for generating sentence embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Extract the 'background' column as feature set X and 'decision' column as target labels y\n",
    "X = data_df['background'].astype(str)\n",
    "y = data_df['decision']\n",
    "\n",
    "# Encode target labels to numerical values using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets with stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# Perform TF-IDF vectorization on the training and testing text data\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Generate sentence embeddings for the training and testing data using SentenceTransformer\n",
    "X_train_bert = np.array(model.encode(X_train.tolist()))\n",
    "X_test_bert = np.array(model.encode(X_test.tolist()))\n",
    "\n",
    "# Save the TF-IDF vectorized data to .npy files\n",
    "np.save('X_train_tfidf.npy', X_train_tfidf.toarray())\n",
    "np.save('X_test_tfidf.npy', X_test_tfidf.toarray())\n",
    "\n",
    "# Save the Sentence-BERT embeddings to .npy files\n",
    "np.save('X_train_bert.npy', X_train_bert)\n",
    "np.save('X_test_bert.npy', X_test_bert)\n",
    "\n",
    "# Save the encoded labels to .npy files\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca098a10",
   "metadata": {},
   "source": [
    "# Model Training and Evaluation Using Grid Search on TF-IDF and SBERT Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3086b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encoded data\n",
    "# Loading precomputed TF-IDF and Sentence-BERT (SBERT) feature vectors, along with training and testing labels.\n",
    "X_train_tfidf = np.load('X_train_tfidf.npy')\n",
    "X_test_tfidf = np.load('X_test_tfidf.npy')\n",
    "X_train_bert = np.load('X_train_bert.npy')\n",
    "X_test_bert = np.load('X_test_bert.npy')\n",
    "\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "# Define a dictionary of models for training\n",
    "# Three machine learning models are chosen: Logistic Regression, Random Forest, and Neural Network (MLPClassifier).\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=10000),\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'NeuralNetwork': MLPClassifier(max_iter=10000),\n",
    "}\n",
    "\n",
    "# Define parameters for grid search\n",
    "# A dictionary specifying hyperparameters for each model to be optimized using grid search.\n",
    "params = {\n",
    "    'LogisticRegression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'n_estimators': [10, 15, 20],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [5, 10, None]\n",
    "    },\n",
    "    'NeuralNetwork': {\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['adam', 'lbfgs']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Grid search and evaluation\n",
    "# Initialize an empty list to store the results of each model evaluation.\n",
    "results = []\n",
    "\n",
    "# Loop through each feature vectorization method (TF-IDF and SBERT)\n",
    "for vec_name, X_train_vec in {'TFIDF': X_train_tfidf, 'SBERT': X_train_bert}.items():\n",
    "    # Select corresponding test set\n",
    "    X_test_vec = X_test_tfidf if vec_name == 'TFIDF' else X_test_bert\n",
    "    \n",
    "    # Loop through each model\n",
    "    for model_name, model in models.items():\n",
    "        # Perform grid search with cross-validation to find the best hyperparameters\n",
    "        grid_search = GridSearchCV(model, params.get(model_name, {}), cv=5, scoring='f1')\n",
    "        grid_search.fit(X_train_vec, y_train)\n",
    "        \n",
    "        # Get the best model and parameters from the grid search\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # Perform cross-validation on the training data to assess model performance\n",
    "        cv_accuracy = cross_val_score(best_model, X_train_vec, y_train, cv=5, scoring='accuracy').mean()\n",
    "        \n",
    "        # Make predictions on both training and testing sets\n",
    "        y_train_pred = best_model.predict(X_train_vec)\n",
    "        y_test_pred = best_model.predict(X_test_vec)\n",
    "        y_test_proba = best_model.predict_proba(X_test_vec)[:, 1]\n",
    "        \n",
    "        # Calculate performance metrics for both training and testing sets\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        precision_train = precision_score(y_train, y_train_pred, zero_division=1)\n",
    "        recall_train = recall_score(y_train, y_train_pred, zero_division=1)\n",
    "        precision_test = precision_score(y_test, y_test_pred, zero_division=1)\n",
    "        recall_test = recall_score(y_test, y_test_pred, zero_division=1)\n",
    "        f1_train = f1_score(y_train, y_train_pred)\n",
    "        f1_test = f1_score(y_test, y_test_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "        \n",
    "        # Store the results in the list\n",
    "        results.append({\n",
    "            'Vectorizer': vec_name,\n",
    "            'Model': model_name,\n",
    "            'Best Params': best_params,\n",
    "            'CV Accuracy': cv_accuracy,\n",
    "            'Train Accuracy': train_accuracy,\n",
    "            'Train Precision': precision_train,\n",
    "            'Train Recall': recall_train,\n",
    "            'Train F1 Score': f1_train,\n",
    "            'Test Accuracy': test_accuracy,\n",
    "            'Test Precision': precision_test,\n",
    "            'Test Recall': recall_test,\n",
    "            'Test F1 Score': f1_test,\n",
    "            'ROC AUC': roc_auc\n",
    "        })\n",
    "        \n",
    "        # Plot and display the ROC curve for the best model\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'Receiver Operating Characteristic - {vec_name} + {model_name}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "# Convert results list into a DataFrame for easier analysis and visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
